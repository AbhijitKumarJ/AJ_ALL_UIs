from fastapi import FastAPI, Request
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from fastapi.responses import JSONResponse
import os

from API.AdvancedLLMChatManager import AdvancedLLMChatManager

llm_manager = AdvancedLLMChatManager()

app = FastAPI()


# Mount the static directory
app.mount("/static", StaticFiles(directory="static"), name="static")

templates = Jinja2Templates(directory="templates")


# class FileContent(BaseModel):
#     filename: str
#     content: str

# class ChatPayload(BaseModel):
#     provider: str
#     model: str
#     message:str


@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    return templates.TemplateResponse(
        "index.html", {"request": request, "title": "FastAPI Example"}
    )


# @app.get("/api/providers/get_all")
# async def get_all_providers():
#     providers = llm_manager.get_providers()
#     return {"status": "success", "data": providers}

@app.get("/api/providers/ollama/models")
async def get_ollama_models():
    models = llm_manager.ollama_provider.get_models()
    return {"status": "success", "data": models}

# @app.get("/api/providers/groq/models")
# async def get_groq_models():
#     models = llm_manager.groq_provider.get_models()
#     return {"status": "success", "data": models}

# @app.get("/api/providers/claude/models")
# async def get_claude_models():
#     models = llm_manager.claude_provider.get_models()
#     return {"status": "success", "data": models}

# @app.get("/api/providers/openai/models")
# async def get_openai_models():
#     models = llm_manager.openai_provider.get_models()
#     return {"status": "success", "data": models}

# @app.get("/api/providers/gemini/models")
# async def get_gemini_models():
#     models = llm_manager.gemini_provider.get_models()
#     return {"status": "success", "data": models}


# @app.post("/api/chat/get_response")
# async def get_chat_response(item: ChatPayload):
#     return {"status": "success", "data": item}

work_folder="./userfiles/"

# @app.post("/create_files")
# async def create_files(file_contents: list[FileContent]):
#     created_files = []
#     for file in file_contents:
#         try:
#             with open(work_folder + file.filename, 'w') as f:
#                 f.write(file.content)
#             created_files.append(file.filename)
#         except Exception as e:
#             return JSONResponse(content={"error": f"Failed to create {file.filename}: {str(e)}"}, status_code=500)
    
#     return JSONResponse(content={"message": f"Files created: {', '.join(created_files)}"})




chat_manager = ChatLogManager()
execution_manager = ExecutionLogManager()

class ChatMessage(BaseModel):
    user_id: str
    message: str
    timestamp: Optional[datetime] = None

class LogEntry(BaseModel):
    user_id: str
    log_type: str
    content: str
    timestamp: Optional[datetime] = None

@app.post("/log_chat")
async def log_chat(message: ChatMessage):
    chat_manager.log_chat(message.user_id, message.message, message.timestamp)
    return {"status": "success", "message": "Chat message logged"}

@app.post("/log_execution")
async def log_execution(log_entry: LogEntry):
    execution_manager.log_execution(log_entry.user_id, log_entry.log_type, log_entry.content, log_entry.timestamp)
    return {"status": "success", "message": "Execution log entry added"}

@app.get("/get_chat_log/{user_id}")
async def get_chat_log(user_id: str):
    log = chat_manager.get_log(user_id)
    if log is None:
        raise HTTPException(status_code=404, detail="Chat log not found for this user")
    return log

@app.get("/get_execution_log/{user_id}")
async def get_execution_log(user_id: str):
    log = execution_manager.get_log(user_id)
    if log is None:
        raise HTTPException(status_code=404, detail="Execution log not found for this user")
    return log


# cmd> uvicorn main:app --reload
